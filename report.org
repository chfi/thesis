#+TITLE: TODO thesis name
#+AUTHOR: Christian Fischer
#+EMAIL: christian@chfi.se

#+LATEX_CLASS: report
#+LATEX_CLASS_OPTIONS: [a4paper]

* Introduction
# v. quick intro to legacy code

# overview of the problems caused by legacy code

# v. quick intro to FP

# overview of the problems solved by FP

** Objective
# see if FP can solve legacy code by developing GGB

** Delimitations
# case study

** "Background" [TODO: Rename]
# BD etc., GSoC

** GeneNetwork 2/Affiliations


* Background/Theory
** Legacy code
# TODO subsections here could use different names
# Section abstract


*** Definition

# What legacy code is - definition
Wikipedia defines "legacy system":
"In computing, a legacy system is an old method, technology, computer system, or
application program, 'of, relating to, or being a previous or outdated computer
system.' [..] This can also imply that the system is out of date or in need of
replacement."


# Why legacy code is a problem; i.e. why I should care that there are legacy systems, statistics
  # Num of legacy systems
  # size of legacy systems
  # impact of legacy systems
  # difficulty to change

TODO statistics on legacy systems; how pervasive are they, how old do they
     tend to be, how expensive is their maintenance and where do most of
     the costs fall

TODO sum up why it's a problem - new features, new data, security issues

TODO point out source code as one problem; not language or OS, since
     that's basically stable these days (i.e. they're unlikely to
     be replaced soon, compared to how fast things moved up until
     the 90s)

Following this, we define a "legacy codebase" to be the codebase of a
system which is "old" and "difficult" to work with. The technology itself
does not matter, only the size and complexity of the codebase itself.
Likewise we do not look at dependencies, a problem solved by pure functional
package managers such as Nix and Guix.
# TODO Nix & Guix refs


When someone wants to change the system. Otherwise, if it's running
smoothly and does everything everyone wants of it, there is no problem.

TODO
- security fixes
- bug fixes
- changes to external dependencies
- changed features
- new features (e.g. electronic healthcare records)


# Why legacy code is a *difficult* problem; i.e. how people have tried (and failed) to solve it
  # or, equivalently, why it is still a problem

# WIP Why is it difficult to do these things, to change legacy code?

# WIP Nobody understands the code => the set of changes that are safe
    # to make are unknown

The main reason it is difficult to work with legacy code is lack
of knowledge of the system and codebase. A lot of work is required
to discover what changes can be done without compromising the
system's current function; one must then come up with a way to
fit in the desired changes (new features, bug fixes, etc.) in
that possible implementation space.
TODO REF

# "The maintenance of legacy code is a hard task since developers do not have
# access to details of its implementation."
# TODO REF: http://ieeexplore.ieee.org/abstract/document/7479256/?reload=true

WIP There is no clear specification of the design or the system
This lack of knowledge can be caused by not having a system specification,
but even if there is one, it is possible (likely?) that the system
has grown past it -- that the specification does not actually
describe the current system. A system specification does
not necessarily help understand the codebase, either.
TODO REF


WIP The system is only partly known; there is no way to test changes
Often there are few or no tests, making it difficult, if not impossible,
to be sure that a change has not caused some kind of regression.
TODO REF

WIP The existing data structures etc. can be arbitrarily complex,
     have old/unused data/fields, be mutated at various places;
     thus it is difficult to know where to start when inserting
     new code
If the system has grown organically over a longer period of time,
the data structures and procedures that manipulate them have likely
also grown to fit new features etc., leading to large pieces of
state that are difficult to reason about. Objects may be doing
something much different from their original purpose. WIP
TODO REF

WIP Some new feature/solution to a new problem may involve
     ""stuff (architecture etc.)"" that the existing code
     is difficult to fit into, or vice versa
The changes that need to be made may fundamentally be "out of phase"
with the existing system. For example, it may require data that
does exist in some part of the system, but the data is tangled
up with other state and so on.

In short, the problem is lack of knowledge in what the system does, and how the
code relates to the system and its parts. It may also be extremely difficult to
know if a change made is safe.

  # to know why it is still a problem we need to know why it became a problem
  # it "became" a problem when it "became", i.e. when its code was written
  # thus: the problem is bad code.

  # subsection outro: legacy code problems are caused by bad code being
  #   difficult to work with, extend, etc.


*** Code quality

It's also desirable to know what makes code more or less difficult to
work with -- both to give a clearer picture of what code to focus on
when refactoring old systems, as well as give programmers guidelines
when developing new code.

# begs the question -- what is bad code?
  # limited definition, but:
    # difficult to know what changes to code produce what changes in output (transformation!)
      # i think this is enough, actually. at least if prim. obs./types can fit in here


  # code smells as heuristics for bad code
    # argue that

In a word, we want heuristics for good vs. bad code. These are called code smells, or antipatterns.

TODO this probably needs... more
First, however, we need to define what is meant by "good" or "bad" code.

Beck & Fowler [TODO REF] provides a list of 22 code smells that have been
used (extensively?) since publication.
(TODO REFs
http://ieeexplore.ieee.org/abstract/document/1235447/
https://link.springer.com/article/10.1007/s10664-006-9002-8
https://dl.acm.org/citation.cfm?id=2629648
http://www.sciencedirect.com/science/article/pii/S0164121215000631
)

Many of the code smells they list, as well as the solutions to them, are
concerned about class-based object-oriented programming (OOP). OOP has
been the primary programming paradigm for decades (TODO REF),
WIP more here (but what?)

  # what is good code?
    # maybe something about the semantic space of the program vs. the implementation space
      # yeah; good code means it is "easier" to know what some change to the code does to the output,
      # and conversely what change needs to be made to produce desired output
      # transformations!

  # list "our" code smells/heuristics
    # code duplication - special case of shotgun surgery (in most cases)
    # implicit state/mutability
    # side effects
    # primitive obsession
    # shotgun surgery (but with better name)
      # i.e. anything that leads to a change in a small part of the output
        # requiring a disproportionately large change in the program code

- Duplicated code - when a piece of code appears multiple times
  in the codebase, it's a sign of a potential abstraction.
  It also makes it difficult to change things, as the change needs
  to be duplicated several times -- which also leads to more opportunities for mistakes to be made.


- primitive obsession - Using primitive types to represent values that could
  be better represented by composite types or wrapped types. This can
  lead to values being used where they shouldn't be (e.g. providing a
  Number representing a pixel to a function expecting a Number actually
  representing the number of objects in an array). This also makes it
  more difficult to understand what a variable or value is to the program.

- shotgun surgery - When functionality is spread out in the codebase in such a way that
  making a change at one place requires making a change at many other places.
  Reduces code comprehension, as distant pieces of code are somehow interacting,
  and makes it more difficult to modify the codebase successfully.

Simply, a good piece of code makes it clear what it does, how it relates
to the system at large, and how it can be changed or reused without
compromising its behavior or the behavior of the system.


*** Solutions
# then we can move on -- how do we *use* these heuristics

Reverse engineering of legacy code exposed
https://doi.org/10.1145/225014.225045

"Reverse engineering of large legacy software systems generally cannot meet its
objectives because it cannot be cost-effective. [..] it is very costly to
“understand” legacy code sufficiently well to permit changes to be made safely,
because reverse engineering of legacy code is intractable in the usual
computational complexity sense."

As one of the main problems of legacy code is lack of knowledge, one
of the main ways to attempt to solve it is to reverse engineer
the existing system. This is usually done manually [TODO REF], but
can also be done using automatic analysis of the code.

# some short side-paths: modularization, automated code analyses

# TODO subsection or paragraph?
**** Code analysis
One common way is to analyze the code to find ways to modularize
it, to decouple the pieces from one another. This can be done
by OOP stuff

Another interesting route is finding a modularization by constructing
a concept lattice based on where different global variables are used.
This lattice can then be used to create descriptions on how to
modularize the codebase.
REF: Assessing Modular Structure of Legacy Code Based on Mathematical
     Concept Analysis
     https://doi.org/10.1145/253228.253354

TODO Problems with these approaches, and to automation of this in general
TODO probably something about machine learning


# the main course: manual reverse engineering

# TODO subsection or paragraph?
**** Manual reverse engineering
this section is not even a section.

The most common (TODO REF) solution is simply to do it by hand. This
requires that programmers look at, and comprehend, the codebase, and
how the codebase relates to the semantics of the system. Writing tests
should also be done to give greater confidence when changes are made.

REF The most common way - Do it by hand.

# a quick exploration of the literature/background in this area, OOP etc.

# finally a summary of the legacy code section, especially
# the causes (code smells) followed by

# a smooth segue (ala "there is, however, one paradigm/potential
# solution that has not been examined...")

** Purely functional programming

# Quick intro to what pure FP is; an abstract, basically.
   # transformations

Functional programming as a paradigm focuses on functions in the mathematical
sense, where functions, with some given input, always produces the same output.
In purely functional programming, this concept taken to its limit, with
functions not being able to perform side-effects, such as reading input from the
user, or updating the user interface; more on these actions below. This is in
contrast to the imperative paradigm, which places no such limitations on
functions, other than scoping.
# TODO Footnote: an imperative language could of course
# provide purity, but it's not exactly common, nor is it a natural part of the
# paradigm).

# Then a deep dive into the most important parts

*** Functional programming
# Where it (FP in general) came from (lambda calc)
   # transformations?
The functional paradigm can be seen as a natural extension to the lambda
calculus, a model of computation invented by Alonzo Church,
# TODO REF
while
imperative programming is closely connected to the von Neumann-style of computer
on which it runs, and is similar to the idea of a Turing machine.
# TODO REF(TODO REF)
Whereas a Turing machine models computation as manipulating symbols on an
infinite tape of memory given a set of instructions,
# TODO REF
the lambda
calculus models computation as function abstraction and application; the name
derives from using \lambda to define functions.
# TODO footnote about lambda/anonymous functions, maybe

The Turing machine and lambda calculus models of computation are (probably) equivalent, by the Church-Turing thesis. Thus
any program that can be run on a theoretical Turing machine can be transformed
to "run" in the lambda calculus. However, while programming languages that
are built on the idea of a Turing machine are notoriously difficult to develop
for,
# TODO REF/FOOTNOTE brainfuck, "turing-tarpits"
and are generally interesting only as curiosities or for research,
# TODO REF
languages based on lambda
calculus are more wide-spread. Indeed, the pure functional language Haskell
is at its theoretical core a typed lambda calculus, based on System-F\omega,
which it compiles to as an intermediate language \cite{haskell2010}.
# TODO REF https://ghc.haskell.org/trac/ghc/wiki/Commentary/Compiler/FC


*** Purity
# What purity is and what it implies (ref transparency)
   # transformations!

Pure FP provides something called "referential transparency", which means that
changing a piece of code to the result of running that code does not change the
program.
# TODO REF
This makes "equational reasoning" possible,
# TODO REF
letting the programmer
reason about parts of the program code as separate from the rest of the program.
It gives the programmer confidence in what a function does.

# How pure FP achieves ref transparency, tying back to code smells/good code heuristics
  # Static types - encoding effects in the types
Functional programming is orthogonal from type systems, but powerful type
systems are closely related to pure functional languages.
# TODO REF.
Haskell, being based on a typed lambda calculus, is a statically typed language,

    # Intro to reading type sigs?
    # Monadic IO
and is an example of using a powerful type system
# TODO define
 to capture effects that are
performed by the program -- that is, letting a purely functional language
express effects such as interacting with the real world
# TODO like 2 refs).

Besides capturing effects, a powerful type system provides the programmer with
tools to increase productivity,
# TODO REF
decrease bugs,
# TODO REF
make refactoring easier,
# TODO REF
and improve the programming experience in multiple ways.
# TODO ref & explanation, type-directed search

# NOTE this is maybe overkill, or could be moved to the PS syntax intro
For example, Haskell and many(most?) other languages with similar type systems,
do not have a `null` value, instead encoding the possibility of lacking a value
in the type system. In Haskell, the type `Maybe` captures this possibility;
if a function produces an `Int`, you can be sure that after calling the function
you do indeed have an `Int`.

# TODO maybe something about the saying "if it compiles, it works" and refactoring
    # Other functor-based effects (Maybe vs. null)

  # Immutability - mutation as side effect
A lower-level part of pure FP, which has seen increased use outside of FP(TODO REF)
is immutability of data. In a purely functional language, functions cannot modify
data passed to them, as doing so would be to perform a side-effect -- passing the
same variable to two functions would not necessarily have the result expected
if one function can modify the input to the other. Using data structures that
are immutable by default makes reasoning about programs much easier as it removes
that possible side-effect, no matter the programming paradigm.

*** Advantages
# Pure FP/a good lambda-calc based type system gives us even more
  # Category theory as 70 years of docs, abstractions

# WIP Category theory as 70 years of documentation in pure FP languages. (Abstractions, good ones!)
As a type system gains features, the number of abstractions that can be expressed
in it increases. Category Theory is a highly abstract branch of mathematics concerned
with `categories` consisting of `objects` and `morphisms` between objects. It is
a rich field of research, and has over 70 years of results -- and ideas and abstractions
from it has been used in programming, especially pure FP. A classic example is
Haskell's use of `monads`, an abstraction which captures the essence of sequential
computation.
# TODO REF
Haskell uses a monadic type for its IO system.
# TODO REF

If a programmer can express their problem in the language of category theory,
they gain access to 70 years of documentation concerning their problem. If the
abstractions used can be expressed in the type system, the compiler can help
prove that the program is correct.

# maybe footnote: for example, everything is an adjunction(TODO REF) and a monoid(TODO REF)

  # Parametric polymorphism & free theorems
    # transformations! e.g. folds, recursion schemes

# Summary of pure FP -- it's all in the types!
    # Summary of pure FP -- transformations, described to the user *and* compiler in the types
# something like "Just a few words, such as (a -> b), should not only tell us what
# the code does, but also tell the compiler what the code should do"

While writing a program in a pure functional language, the programmer
is encouraged by the language and environment to write code that is
reusable and easy to reason about [REF Why functional programming matters].
You also get some level of program correctness, by writing code
using types that correspond to the program semantics. You're able
to construct transformations between data structures and compose
them together -- all type-checked by the compiler.

# another smooth segue (zipping the previous two sections together...)
# i.e. "Next it is argued why pure FP can help with the problems of legacy code"


** Functional programming for legacy codebases
# section needs a better name. later.

# intro - the various (apparent) causes for problems of legacy code
  # are analyzed from the viewpoint of pure FP


# code duplication

# primitive obsession

# side effects

# mutability

# summary - by eliminating side effects & giving the programmer tools to know
   # what various parts of the system do,
   # pure FP appears to be usable to limit the problems that lead to legacy code problems



* Method
# Introduction to the method - evaluating pure FP as a tool for extending legacy code bases
** Biodalliance
# Describe BD, its history, etc.

** Purescript


** Genetics Graph Browser/Evaluation
# specify the product

# detail how the product is developed,
# and how it connects to & extends the BD legacy codebase

# list the parts of BD/GGB where legacy-type problems were an issue
  # i.e. the parts that are detailed in results (and why they were chosen)

# explain how this answers the research question (case study)


* Results

#+INCLUDE: "./bdcy.org" :minlevel 2

# *** Cytoscape.js

#+INCLUDE: "./config.org" :minlevel 2

# *** Units

#+INCLUDE: "./units.org" :minlevel 2

# *** Rendering

#+INCLUDE: "./glyph.org" :minlevel 2

# *** Events

#+INCLUDE: "./events.org" :minlevel 2

# UI

#+INCLUDE: "./ui.org" :minlevel 2

** The Completed Product

# Present the finished browser!

# What it looks like

# How it's used


* Discussion



* Conclusion


* Bibliography


# \nocite{*}
\bibliographystyle{plain}
\bibliography{bibliography}
