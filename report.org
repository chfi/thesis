# -*- eval: (let () (org-babel-goto-named-src-block "setup-export-class") (org-babel-execute-src-block)); -*-

#+TITLE: TODO thesis name
#+AUTHOR: Christian Fischer
#+EMAIL: christian@chfi.se

# Define custom org-latex-class for exporting with correct headers
#+NAME: setup-export-class
#+BEGIN_SRC emacs-lisp :exports none :results none
  (add-to-list 'org-latex-classes
               '("thesis-report"
                 "\\documentclass[11pt]{report}"
  ("\\chapter{%s}" . "\\chapter*{%s}")
  ("\\section{%s}" . "\\section*{%s}")
  ("\\subsection{%s}" . "\\subsection*{%s}")
  ("\\subsubsection{%s}" . "\\subsubsection*{%s}")
  ("\\paragraph{%s}" . "\\paragraph*{%s}")))
#+END_SRC

#+begin_comment
#+BEGIN_SRC emacs-lisp :exports none :results silent
  (add-to-list 'org-latex-classes
               '("thesis-report" "\\documentclass[11pt]{report}"
  ("\\part{%s}" . "\\part*{%s}")
  ("\\chapter{%s}" . "\\chapter*{%s}")
  ("\\section{%s}" . "\\section*{%s}")
  ("\\subsection{%s}" . "\\subsection*{%s}")
  ("\\subsubsection{%s}" . "\\subsubsection*{%s}"))
#+END_SRC
#+end_comment

#+BIND: org-export-filter-plain-text-functions (tmp-f-symbols)
#+BEGIN_SRC emacs-lisp :exports results :results none
(defun tmp-f-symbols (text backend info)
  (when (org-export-derived-backend-p backend 'latex)
        (replace-regexp-in-string "<>" "\Diamond" text)))
#+END_SRC


#+LATEX_CLASS: thesis-report
#+LATEX_CLASS_OPTIONS: [a4paper]


#+LATEX_HEADER: \usepackage[numbers]{natbib}
#+OPTIONS: H:6


* Introduction

# TODO Have this here or in Background/Theory?
#+BEGIN_QUOTE
Legacy code. The phrase strikes disgust in the hearts of programmers.
It conjures images of slogging through a murky swamp of tangled
undergrowth with leaches beneath and stinging flies above. It conjures
odors of murk, slime, stagnancy, and offal. Although our first joy of
programming may have been intense, the misery of dealing with legacy
code is often sufficient to extinguish that flame. --- Robert C.
Martin, Foreword to Working Effectively with Legacy Code
\cite{feathers2004working}
#+END_QUOTE

# v. quick intro to legacy code

# overview of the problems caused by legacy code

# v. quick intro to FP

# overview of the problems solved by FP

** Objective
# see if FP can solve legacy code by developing GGB

# TODO briefly introduce GN2 and BD
# TODO introduce problems w/ BD
# TODO introduce GGB as solution to problems;
# TODO purpose: explore FP as solution to JS legacy garbo


** Delimitations

This thesis concerns a single programming project and a single programmer;
it is a case study more than anything else, and so cannot be taken as
definite evidence.
# TODO this: However, it is hoped that

** Background/Context/Motivation
# GN2, BD etc., GSoC

** GeneNetwork 2/Affiliations


* Background/Theory
The prerequisite theory for the thesis project is introduced. A definition
of "legacy code" is given, followed by relevant statistics, facts, and
techniques concerning legacy code and working with it. This is followed by an introduction
to the purely functional programming paradigm.



** Legacy code
# TODO subsections here could use different names
# Section abstract


*** Definition

# What legacy code is - definition
# Wikipedia defines "legacy system":
# "In computing, a legacy system is an old method, technology, computer system, or
# application program, 'of, relating to, or being a previous or outdated computer
# system.' [..] This can also imply that the system is out of date or in need of
# replacement."

There is no formal definition of "legacy code", but \cite{feathers2004working}
gives the definition "Legacy code is code that we've gotten from someone else."
\citeauthor{Bennett1995} provides a definition of legacy systems in general, which
gives an idea of why it may be problematic: "large software systems that we don't know how to cope with but that are vital to
our organization" \cite{Bennett1995}.
Finally, \citeauthor{weide1995reverse} gives a definition closer to the
spirit of the concept as experienced by programmers working with
legacy systems --- in the trenches, as it were:

#+BEGIN_QUOTE
[..] legacy code, i.e., programs in which too much has been invested
just to throw away but which have proved to be obscure, mysterious,
and brittle in the face of maintenance.
#+END_QUOTE

In other words, legacy code is code that continues to be relevant, e.g. by
providing a service that is important, and that requires modification,
or will require modification. If there were never going to be any reason to
modify the code, it would not be worth talking about, nor is it likely that
a system that provides a continually valuable service will not at some point
in the future require maintenance or new features \cite{lehman1980programs}.

# TODO could maybe do with a bit more
# WIP statistics on legacy systems; how pervasive are they, how old do they
     # tend to be, how expensive is their maintenance and where do most of
     # the costs fall

For this reason, legacy systems are prevalent in the world.
If a system works as it should, providing the service that is needed,
and said service must continue to be provided, the safest thing to do
is to leave it as is --- until it is decided, for whatever reason, that
changes must be made.

The U.S. goverment federal IT budget for 2017 was over $89 billion, with
nearly 60% budgeted for operations and maintenance of agency systems,
with a study by the U.S. Government Accountability Office finding that
some federal agencies use systems that are up to 50 years old \cite{gao2016legacy}.

# TODO Footnote The Danger of Legacy Systems https://web.archive.org/web/20120323165836/http://www.mousesecurity.com/?p=220


Many of these federal agency systems consist of old hardware, old operating
systems, etc., however the problems of a legacy system do not need to be
caused by such factors. The code itself is often the problem \cite{Bisbal1999},
and is what this thesis is concerned with.

# TODO maybe move this paragraph, and maybe the previous one, to a more suitable position
We define a "legacy codebase" as the codebase of a legacy system,
where the problem of modifying the system is constrained by the code
itself --- the underlying technology is not relevant. Likewise we do not look
at dependencies, a problem solved by pure functional
package managers such as Nix \cite{dolstra2004nix} and Guix \cite{courtes2013functional}.

Why would changes need to be made to a legacy codebase? When the
behavior of the system needs to be changed. \cite{feathers2004working}
identifies four general reasons:

# TODO Maybe add examples?
# - security fixes
# - bug fixes
# - changes to external dependencies
# - changed features
# - new features (e.g. electronic healthcare records)
  1. Adding a feature
  2. Fixing a bug
  3. Improving the design
  4. Optimizing resource usage

All of these somehow modify the behavior of the system; if there was
no change in the system behavior, the change in code must have been
to some part of the codebase that isn't used! Thus, the desired change
requires a change in behavior. The problem with legacy code is that
it is difficult to know how to make the change to the code that produces
this desired change in behavior, and /only/ the desired change.


# Rewrite & use these two paragraphs if more concrete examples are desired
# *maaaybeeee* include this
# WIP The existing data structures etc. can be arbitrarily complex,
#      have old/unused data/fields, be mutated at various places;
#      thus it is difficult to know where to start when inserting
#      new code
# If the system has grown organically over a longer period of time,
# the data structures and procedures that manipulate them have likely
# also grown to fit new features etc., leading to large pieces of
# state that are difficult to reason about. Objects may be doing
# something much different from their original purpose. WIP
# TODO REF

# also *maaaybeeee* include this
# WIP Some new feature/solution to a new problem may involve
#      ""stuff (architecture etc.)"" that the existing code
#      is difficult to fit into, or vice versa
# The changes that need to be made may fundamentally be "out of phase"
# with the existing system. For example, it may require data that
# does exist in some part of the system, but the data is tangled
# up with other state and so on.

# Why legacy code is a *difficult* problem; i.e. how people have tried (and failed) to solve it
# or, equivalently, why it is still a problem

# WIP Why is it difficult to do these things, to change legacy code?
#     Nobody understands the code => the set of changes that are safe
#     to make are unknown


The main reason it is difficult to work with legacy code is lack of
knowledge of the system and codebase, and how the system's behavior
relates to the underlying code. Legacy codebases often lack
documentation and tests, without which a new programmer on the project
has few, if any, tools at their disposal to understand the codebase as
it is, since they do not have any knowledge of how and why the code
came to be as it is. Even if there is a design or system specification
--- which is far from certain --- it is not necessarily accurate. The
code may very well have grown beyond the initial specification, and
the specification need not have been updated in step with the code.

For these reasons, one of the main problems of working with legacy
code is understanding it in the first place \cite{feathers2004working}
\cite{Bennett1995} \cite{siebra2016anticipated}. This is also a
difficult, time-consuming process, and one of the reasons reverse
engineering legacy systems is rarely, if ever, a cost-effective
undertaking \cite{weide1995reverse}. Also according to \citeauthor*{weide1995reverse},
even if a system is successfully reverse engineered and modified,
even if a /new/ system is successfully developed that provides
the same behavior as the legacy system but with a better design,
it is highly likely that the new system, eventually, reaches
a point where it too must be reverse engineered --- i.e. when the
"new" system becomes another legacy system, and the cycle begins anew.
# TODO we can drop a reference to samsara & nirvana here somewhere

In short, the problem with legacy code is lack of knowledge in what
the system does, and how the code relates to the system and its parts.
This makes it difficult to know what changes to make to the code to
produce the desired change in system behavior, and if a change made is safe,
i.e.\ that /no/ undesired change in system behavior results.


*** Solutions

Legacy code has been a recognized problem for decades, and people have
been trying to solve it for as long.
\cite{lehman1980programs}
\cite{weide1995reverse}
\cite{Mntyl2006}
This section will present some general approaches and tools that have
been applied when working with legacy systems. First, techniques that
help with manual reverse-engineering --- the most widely used approach
to solve legacy code problems --- are introduced, followed by a brief
walk through some automated tools.

**** Reverse engineering legacy systems

Reverse engineering a system can be very difficult and time-consuming,
even with access to the source code \cite{weide1995reverse}. There are
entire books dedicated to the subject of understanding a legacy codebase
and working with it to transform it into something more easily understood
and extended \cite{feathers2004working}.

As previously mentioned, the
greatest problems stem from insufficient knowledge of the system; from
not knowing what code does, or what happens when a change is made.
Thus, adding tests is one of the main tools for increasing understanding,
as tests provide the programmer with feedback on their code changes.
\cite{siebra2016anticipated}
However, this feedback is only as good as the test suite; if a
system behavior is not covered by the tests, the programmer has a blind
spot in that area.
Where and how to add tests is an art and science of its own, as the
programmer must find what parts of the system need to be tested, and
how to insert the tests into the codebase. This becomes more difficult
when a program has many tightly-knit parts, global state, etc.
# TODO REFs

With a robust test suite, a programmer can modify the codebase to improve the code quality
and architecture of the system, confident that their changes do not
compromise the system's behavior.

# TODO note that these are largely concerned with OOP->OOP or procedural->OOP


**** Automated approaches

Automated tools that assist with legacy systems are largely concerned
with increasing the knowledge of the system, understanding how it works,
extracting modules, etc. One example
is extracting OOP abstractions such as classes from imperative code,
e.g. by analyzing which functions and variables are used together.
\cite{Etzkorn1997}
\cite{Silva2017}

# TODO this paragraph may be wrong :) read the paper
Another interesting route is creating a "modularization proposal," i.e.
a series of architectural changes to the codebase that lead to a
more modular system while minimizing change each step,
by constructing
a concept lattice based on where different global variables are used.
This lattice can then be used to create descriptions on how to
modularize the codebase. \cite{lindig1997assessing}

Another approach is using automated tools to detect potentially
problematic parts of a codebase, such as overly complex controllers
in GUI applications \cite{Lelli2016},
or code that is simply more likely to be buggy, based on statistical
analyses \cite{Ray2016}. These would help programmers find what parts
of the codebase to target.

# TODO Linters?

# TODO probably something about machine learning

Some ways that developers and researchers have attempted to fix
legacy codebases have been introduced, however one question
still remains: what is it with legacy code that makes it
problematic? Is there some attribute of the code itself, or
is /all/ code that successfully solves a problem doomed to
become "legacy" code? I.e., is it possible to write code that
is "legacy"-resistent?

# TODO REFS need to show that it is in fact possible to write code
# that avoids/reduces the problems. GNU, Linux, etc. would be good.

We have identified that the problems seem to be related to
understanding the code. From that viewpoint, the question becomes: is
there a way to write code that is more easily understandible, and if
so, what characterizes it? This is what the next section seeks to
answer.

*** Code quality

#+begin_comment
Knowing what code is safe to change & knowing what code *to* change
  -> Good code is code that tells the programmer what it does,
     but also what it does *not* do.

Describe code smells wrt. that
#+end_comment

The problems of legacy code revolve around knowing what different
parts of the codebase do; what changes in code lead to what changes
in behavior, and what changes in code do not lead to changes in
a subset of the system behavior. "Good" code could, then, be defined
as code which:

1. Tells the programmer what it does
2. Tells the programmer what it does *not* do

Conversely, "bad" code makes it difficult to see why it exists,
why it is called, and what effects it has, and does not have,
on the system behavior.

These definitions only beg further questions, however, and require
deeper investigation.

**** Knowing what a piece of code does
     means knowing what data it requires to do whatever it is it does,
i.e. what other code it depends on, and knowing what effects it has
on the system behavior.
This may sound simple, but a function or method
can easily grow to the point where it is difficult to see what the
dependencies truly are, e.g. if a compound data type is provided
as the input to a function, is every piece used? If so, how are those
pieces created; what parts of the codebase are truly responsible for the
input to the function? Knowing what code calls the function is not
enough unless the call site is entirely responsible for the input.
# TODO REF, working with legacy code or

While dependencies may be difficult to unravel, the opposite problem
is often much worse.
# TODO REF
Knowing what effects a piece of code has on the system can be extremely
difficult in commonly used languages such as Java and Python,
# TODO REF, why FP matters? something like that
as there is often little limiting what some function or method can
do. A given method may perform a simple calculation on its input
and return the results. It may also perform an HTTP request to some
service and receive the results that way -- with no indication that
the system communicates with the outside world in this manner, nor
that the system /depends/ on said service. It could also modify global
state, which potentially changes the behavior of all other parts of
the codebase that interact with said state, despite there being no
direct interaction between the different parts. This has been called
"spooky action at a distance,"\cite{feathers2004working} a reference
to what Einstein thought of quantum mechanics.
# TODO REF or footnote for Einstein

# TODO keep this or the "spooky action at a distance" quote
#+BEGIN_QUOTE
Most large software systems, even if apparently well-engineered on
a component-by-component basis, have proved to be incoherent as a
whole due to unanticipated long-range "weird interactions" among
supposedly independent parts. \cite{weide1995reverse}
#+END_QUOTE

# TODO add appropriately convoluted example (with misleading function names)
#+begin_comment
#+BEGIN_SRC c
int globalValue = 0;

int rq(int x) {
   globalValue++;
   return x + globalValue;
}

int rt(int x) {
   return x + 1;
}
#+END_SRC
#+end_comment


**** Knowing what a piece of code does not do
# TODO this needs to be reworded & expanded.
#      my point is regarding that knowing that some function F
#      is one place to change the code to produce the desired system change,
#      does *not* imply knowing that said modification *only* produces the desired behavior change.
#      Probably best to bake together this and the previous subsubsection/paragraph
     is, for the above reasons, difficult in many languages. In fact,
while these two questions may appear very similar, it is often not the
case that knowing the answer to one of them lets the programmer deduce
the answer to the other.
# idk if this is right


**** Good code
     must then, somehow, communicate as much information to the programmer
as possible. At the same time, throwing too much information at the programmer
will not help.
# TODO REF cognitive psychology or something; too much shit is bad, obv.
We have seen that legacy code is often if not always imperative code, and
that the OOP paradigm has been an oft-tried solution for legacy code. Despite
this, many current legacy code systems are written in OOP languages such as
Java, and while books provide dozens of ways to write good OOP code, and ways
to reduce the problems of legacy code, there does not seem to be any reason
to believe that OOP is the ultimate solution to legacy code, nor that OOP code
is inherently the best type of code.
# TODO this will require more references and/or argumentation


Object-oriented is not the only way to write code. Functional programming (FP) is
a programming paradigm that takes quite a different approach than OOP, and
purely functional programming provides tools to assist the developer in writing
what we have now defined to be "good" code. The next section provides an
introduction to the area and its ideas.


** Purely functional programming


This section introduces the purely functional programming (pure FP) paradigm,
and its strengths. In short, pure FP enforces "referential transparency,"
which means that any piece of code can be replaced with the value it evaluates
to, wherever it appears in the source code. This makes it easier to understand
the code, any function can be reduced, on a cognitive level, to a black box
that can be passed around and used without having to think about its contents.
\cite{hughes1989functional}

Pure FP achieves this by using immutable data structures, eliminating side effects
in code, and using a powerful type system to express effectful computations
(e.g. code that interacts with the user).
# TODO REFs?


*** Functional programming
# Where it (FP in general) came from (lambda calc)
   # transformations?
The functional paradigm can be seen as a natural extension to the lambda
calculus, a model of computation invented by Alonzo Church, where a
small set of variable binding and substitution rules is used to express
computations.
# TODO REF

# On the other hand,
# imperative programming is closely connected to the von Neumann-style of computer
# on which it runs, and is similar to the idea of a Turing machine.
# TODO REF

# TODO this paragraph could use some more work; give examples of Turing machine-based "languages" e.g. brainfuck
The Turing machine and lambda calculus models of computation are equivalent
\cite{turing_1937}. However, while the Turing machine model is largely
an abstract concept that is useful for modeling computation, but less so
in actually solving programming problems, there are several actively used
languages that are, at their core, some type of lambda calculus. One
example is the purely functional language Haskell. The Glasgow Haskell Compiler,
the de facto standard Haskell implementation, compiles to a language based
on System-F\omega, a typed lambda calculus, as an intermediate language
\cite{haskell2010} \cite{ghcguide}.


# TODO s/main/only/?
The main tool in the lambda calculus is defining and applying functions;
unsurprisingly, functions are the focus of FP. In this case, "function"
is defined in its mathematical sense, as a mapping from inputs to outputs,
rather than the sense of a function in e.g. the C programming language,
where it is rather a series of commands for the computer to execute.

In FP, then, if any function $f$ is given some input $x$ and produces some
output $y$, it must /always/ be the case that $f(x) = y$. Thus, wherever
$f(x)$ (for this given $x$) appears in the code, it can be replaced with $y$,
without changing the program behavior whatsoever. Conversely, if we have
that $g(a) = b$, but calling $g(a)$ prints a value to a console window,
$g$ is /not/ a function in this sense, as replacing $g(a)$ with $b$ in
the code would change the program behavior by not printing to the console.
This characteristic is what is meant by "purity".


*** Purity
# What purity is and what it implies (ref transparency)
   # transformations!



While it is possible to write pure functions in any language that supports
functions, purely functional languages, such as Haskell have features that
ensure that functions are in fact pure. Haskell in particular handles this
through its powerful type system.


# Static types - encoding effects in the types
# Functional programming is orthogonal from type systems, but powerful type
# systems are closely related to pure functional languages.

# Immutability - mutation as side effect
# TODO REF
# is immutability of data. In a purely functional language, functions cannot modify
# data passed to them, as doing so would be to perform a side-effect -- passing the
# same variable to two functions would not necessarily have the result expected
# if one function can modify the input to the other. Using data structures that
# are immutable by default makes reasoning about programs much easier as it removes
# that possible side-effect, no matter the programming paradigm.

# Intro to reading type sigs?
# Monadic IO

# NOTE this is maybe overkill, or could be moved to the PS syntax intro
# For example, Haskell and many(most?) other languages with similar type systems,
# do not have a `null` value, instead encoding the possibility of lacking a value
# in the type system. In Haskell, the type `Maybe` captures this possibility;
# if a function produces an `Int`, you can be sure that after calling the function
# you do indeed have an `Int`.

# TODO maybe something about the saying "if it compiles, it works" and refactoring
    # Other functor-based effects (Maybe vs. null)

# A lower-level part of pure FP, which has seen increased use outside of FP

*** Advantages
# Pure FP/a good lambda-calc based type system gives us even more
  # Category theory as 70 years of docs, abstractions

# WIP Category theory as 70 years of documentation in pure FP languages. (Abstractions, good ones!)
# As a type system gains features, the number of abstractions that can be expressed
# in it increases. Category Theory is a highly abstract branch of mathematics concerned
# with `categories` consisting of `objects` and `morphisms` between objects. It is
# a rich field of research, and has over 70 years of results -- and ideas and abstractions
# from it has been used in programming, especially pure FP. A classic example is
# Haskell's use of `monads`, an abstraction which captures the essence of sequential
# computation.
# TODO REF
# Haskell uses a monadic type for its IO system.
# TODO REF

If a programmer can express their problem in the language of category theory,
they gain access to 70 years of documentation concerning their problem. If the
abstractions used can be expressed in the type system, the compiler can help
prove that the program is correct.

# maybe footnote: for example, everything is an adjunction(TODO REF) and a monoid(TODO REF)

  # Parametric polymorphism & free theorems
    # transformations! e.g. folds, recursion schemes

# Summary of pure FP -- it's all in the types!
    # Summary of pure FP -- transformations, described to the user *and* compiler in the types
# something like "Just a few words, such as (a -> b), should not only tell us what
# the code does, but also tell the compiler what the code should do"

While writing a program in a pure functional language, the programmer
is encouraged by the language and environment to write code that is
reusable and easy to reason about [REF Why functional programming matters].
You also get some level of program correctness, by writing code
using types that correspond to the program semantics. You're able
to construct transformations between data structures and compose
them together -- all type-checked by the compiler.


#+begin_comment
summary of the Background chapter

briefly describe the concepts of legacy code and FP;
  but leave the details of how they interact for the Method section

outro by asking that question -- how do they interact? esp. from an FP viewpoint
#+end_comment


* Method

#+begin_comment
Introduces the method
  i.e. how I went about evaluating pure FP by way of PS as a tool for extending
       legacy code bases and minimizing potential future (legacy) problems of a new code base

First introduce pure FP as a potential tool for legacy code,
looking at specific features and how they correspond to (solving/preventing)
problems

then frame hypothesis

finally present BD & GGB; describe project


#+end_comment

# TODO this quote should fit in somewhere in the Method section
#+BEGIN_QUOTE
I think the lack of reusability comes in object-oriented languages,
not functional languages. Because the problem with object-oriented
languages is they’ve got all this implicit environment that they carry
around with them. You wanted a banana but what you got was a gorilla
holding the banana and the entire jungle.

If you have referentially transparent code, if you have pure functions
— all the data comes in its input arguments and everything goes out
and leave no state behind — it’s incredibly reusable.
--- Joe Armstrong\cite{seibel2009coders}
#+END_QUOTE

# TODO THIS
The purpose of this thesis was to evaluate whether pure FP can be a tool for
working with legacy codebases. ___

This chapter begins with arguments in favor of the hypothesis,
enumerating some features of pure FP that appear advantageous for
limiting the potential problems associated with legacy code. Next, the
programming project that is the core of the thesis, the Graph Genetics
Browser (GGB) is introduced, followed by how the hypothesis was
evaluated in the context of this project.



** Functional programming for legacy codebases
# section needs a better name. later.

#+begin_comment
intro - the various parts of FP we're going to make use of,
  and how they help wrt. the problems related to legacy code


Static types
Abstractions
  Semigroup & monoid
Generative testing (esp. checking typeclass laws)
more..

wrt. assisting the programmer in knowing what code does and does not do
use code smells only as shorthand for specific causes of this
    code duplication --
      more similar pieces of code -> more places to look; less clarity of what to change & effects of change
      e.g. *why* are there multiple similar pieces of code? are they really the same? scope etc.
      DRY principle

    primitive obsession -- less clear
    side effects -- obvious
    mutability -- obvious

summary - by eliminating side effects & giving the programmer tools to know

  pure FP appears to be usable to limit the problems that lead to legacy code problems
#+end_comment

Purely functional programming has many tools and features that are likely
to limit the problems of legacy code. This section begins by introducing
the programming language used in the thesis project, and continues with
providing examples of language features that are likely to reduce the
legacy code-related problems and code patterns in general.

*** Introduction to PureScript
PureScript (PS) is a purely functional programming language in the style
of Haskell, that compiles to JavaScript (JS).
# TODO REFS
PS is immutable by default, free of side-effects, and has an advanced
strict static type system that gives the programmer many tools to increase
productivity and program correctness.
# TODO REFS

# Continue by filling in these subsections wrt the above `Code quality` ideas

*** Immutability

*** Purity

*** Type system
**** Row types?


** Extending a Legacy System


#+begin_comment
present BD as legacy code project; including examples of previous work on extending it etc.
present GGB as both extending & a new platform, with intro to purescript

Evaluation of the hypothesis as comparing the resulting code (or a subset of it)
to the code smells and the respective code in BD (where applicable).
If correct -- or at least not obviously incorrect -- the resulting code should
be free of the code smells.
#+end_comment


In this section, the legacy system that was extended --- Biodalliance --- is described.
The extent and nature of the changes, and more details of the resulting application,
are also given.

*** Biodalliance

# Describe BD, its history, etc.

Biodalliance (BD) is an open source (BSD licensed) HTML5-based genome
browser written in JavaScript (JS) \cite{down2011dalliance}. It is
fast, supports several data formats commonly used in bioinformatics,
and the plots displayed can be configured and customized. Since it is
HTML5-based, it can be embedded into any web page and does not require
any special tools to be used. It also supports exporting images as
SVG, which can be used as high quality figures in publications.

# TODO example of difficulties: adding CSV sources; horizontal rulers; /new/ plot types

# TODO context of wanting to use BD -- GN2
# TODO Why BD?
#      It's proven to work
#      configurations & data exist
#      supports many formats
#      configurable
#      fast

# TODO make sure GN2 has already been introduced...
# TODO maybe more on why we want these features
For GN2 we want a genome browser that supports these features.
We also want to be able to add new features, however BD has shown itself
to be difficult to work with and extend, for reasons earlier defined
as legacy code problems[fn:gsoc2016-footnote]. BD has been in development
since 2010, and as of December 2017 consists of 17.5k lines of JS code
(sans comments and whitespace) split into 61 files.
# TODO footnote to BD github
The codebase has grown organically over time, and has become complex,
with single pieces of functionality (such as rendering data to the
HTML5 canvas) being split into several large functions in different
files, and less than clear flow of control.

[fn:gsoc2016-footnote] The author previously worked on extending BD as
part of Google Summer of Code 2016, and encountered some difficulties:
https://chfi.se/posts/2016-08-22-gsoc-final.html

# TODO Why not BD?
#      JS is untyped
#      JS provides no facilities for supporting the programmer
#      big codebase
#      legacy!!!

We want many of the features of BD, which have required much time and
effort to be implemented. However, we also want new features, but the
time and effort required to implement them in BD is much greater than
necessary due to the legacy aspect of BD's codebase.

# TODO idk about this wording
The solution that was decided upon was to develop a new genome browser.
This browser would allow embedding BD within it, and so be compatible
with BD and support the desired features. However, it would be a
separate application, and be independent of BD's baggage.
This application is the Genetics Graph Browser, to which the next section is dedicated.


*** Genetics Graph Browser

The Genetics Graph Browser was written in PS. It begun as a tool for
constructing BD-compatible data structures for creating new ways to
plot data, but soon grew to a web application that wraps BD and Cytoscape.js.
# TODO note that this will be detailed in Results (Glyph)

# TODO give more details on GGB! give a basic overview of the project "as planned"
# TODO add Main features -- i.e. the parts that are in Results

Throughout its development, various legacy-type problems were encountered
in BD, and avoided or solved in GGB. As GGB is written in PS, this was
done using various "features" of FP, as listed above. In this way,
the GGB project can be seen as a case study in working with legacy code
using purely functional programming.

The hypothesis of this thesis was then evaluated by examining if
and how pure FP helped with these "legacy problems," both when
fixing problems or improving how a problem was solved in BD, including
the parts of GGB that interact with BD, as well as parts of
GGB that are not related to BD, but solutions to which would
likely end up exhibiting legacy-style problems.

# The hypothesis was evaluated by identifying legacy code-type problems
# in BD, then "solving" them by implementing similar functionality
# in GGB, using FP techniques.

# However, it was never the purpose to solve them in that way;
# it's simply how the problems were "naturally" solved in PS.


** Summary

# Summarize how we evaluate the hypothesis with this
The hypothesis, that functional programming techniques can help when
working with an existing legacy code base, as well as lead to code
that is less likely to exhibit legacy code problems in the future,
was tested by developing an application in Purescript that both
interfaces with an existing legacy genome browser, and is intended
to be a stand-alone browser in the future.

Identifying features whose implementation were already cause for concern in
BD, or had the potential to be implemented in problematic ways in GGB,
and if and how FP helped reduce or eliminate those problems, provides
a lens through which it was possible to make some judgements as to
the validity of the hypothesis.


* Results

#+begin_comment
The results are presented

First an introduction of the "completed" GGB -- its features and scope

Then a walk through the code:
  each section corresponds to one module or part of the GGB, and looks like:
    problems in BD wrt. legacy code (code smells) are presented
    the code in GGB is presented as one way of solving those problems
    (or, present each section as a transformation)

The sections:

  bdcy:   extracting a minimal usable interface from JS APIs
          enforcing safety with types
          mapping JS functions to law-abiding abstractions (Semigroup, Monoid)
      smells:

  config: configuring the browser in a type-safe manner
          validating at launch with type-checking and helpful error messages
          mapping GGB config to BD and Cy.js configuration
      smells:

  units:  type-checking domain-specific operations
          more assistance from the compiler in ensuring semantics of program
          compiler-checked documentation
      smells:

  glyph:  using pure FP abstractions to create an extensible transformation pipeline
            for working with various display and input methods
          semigroups and monoids + generative testing = verification
          creating a language that "compiles" to BD-compatible data structures
            but also is extensible
      smells:

  events: transforming events between "disjoint" JS apps with configuration for free
          exploiting JSON's tree structure for a kind-of type-safe system
      smells:

  ui:     fitting BD and Cy.js into a type-safe UI library;
            tying it all together
          type-safe and extensible, with error-checking from many of the previous sections
      smells:


End with summing up where the various code smells showed up in BD,
and how they were solved with FP/PS in GGB.
#+end_comment



** The Completed Product

#+begin_comment
A brief section serving to provide the reader with an image or two to
anchor the rest of the results section to, and prepare them with a
basic framework to fit the examples to.
#+end_comment

# Present the finished browser!

  # What it looks like

  # How it's used -- show basic functionality with screenshots

  # Figure to refer to concepts such as "tracks", "feature", "glyph" etc.

# Outro


** Interfacing with existing JS
# or: transforming JS APIs to PS APIs (kind of)

#+INCLUDE: "./bdcy.org"


** Safe application configuration
# or: transforming user configuration to safe application options

#+INCLUDE: "./config.org"


** Working with units
# or: domain-based type checking of transformations
#     (or something like that)

#+INCLUDE: "./units.org"


** Transforming data for screen and space

#+INCLUDE: "./glyph.org"


** Transforming events between tracks

#+INCLUDE: "./events.org"


** The User Interface
# or: transformations between user and application (or something like that)

#+INCLUDE: "./ui.org"


** Summary

# Summarize by selecting a few code smells and briefly describing,
# conceptually, how they were removed/avoided/bypassed



* Discussion

The resulting browser, GGB, fills the specified requirements, and the
codebase does as well. Purescript was not a magic bullet, and some
problems were experienced during development, however the source code
on the whole does not, arguably, suffer from the problems of legacy
code as defined in this report.


#+begin_comment

Discuss results -- each of the code parts (subsections from Results)

Does the various FP features/tools from the Method help in producing
"good" code in the Results?

On a higher level, is the resulting codebase "easy" to understand,
and to work with? How difficult is it to understand the overall
architecture, to know what areas to change, and what changes in
system behavior ones' modifications to the code leads to?
  And how much of this can be attributed to FP?
  This will all need to be argued for.

How do the various parts from the Background/FP section fit in?
  Purity
  Static types
  (CT) Abstractions

Discuss refactoring; something that happened many times during the project,
  and something a good type system assists with to a great extent

Discuss future work *on GGB*, i.e. predict how easy it will be to extend;
  how the abstractions will help or hinder this, and why

Concede that it is entirely possible to write "bad" code in PS
also that pure FP and PS have their own antipatterns/code smells
  (though I'm not sure if they're comparable to imperative/OOP ones wrt.
   their effect on codebases)



Sections:
how does it fill the requirements? both browser & codebase (brief)
what problems were encountered during development?
why does it not suffer from legacy problems?
  1. why do we think it does not
  2. why do we think that the reason it does not is due to FP/PS

learning PS during development -- something that will happen "IRL" as well


#+end_comment


The code from the previous chapter is examined to see if and how it
stuck to the ideas of "good" code, including what FP features
contributed. Problems experienced during development are presented,
and some examples of how GGB will be extended in the future are given,
together with estimates on how "easy" the addition of those parts to
the codebase and system will be. The potential ways to extend the
browser are also looked at from the view of BD, to examine how
difficult it would be to extend BD without the support of GGB.



# TODO maybe combine these two following sections
** Purescript as a tool for working with legacy JS
# TODO PS is an excellent tool for working with legacy JS projects;
# at least when you have a small number of "injection points", e.g. glyphs in BD

# TODO caveat: BD was relatively well modularized, and some previous
# work had been done on BD to make it so; it was fairly easy to know what to do and where

# TODO is it worthwhile to embed JS apps in a PS app

# TODO maybe notes on PS FFI, row types, records. idk


** Purely functional programming
# ** Functional programming and code quality

# TODO FP encourages "better" code, but does not enforce it; however
# it often becomes more difficult to write bad than good code

# TODO inverting the imperative idea of the callee controlling
# effects is one of the most important parts

# TODO tendency to become difficult to read; terse, implicit
# information in types (need better docs).

** Would JS have sufficed?
# i.e. would GGB have been possible with JS only

# TODO would the codebase be of similar quality, and would the progress timeline be the same


# TODO maybe move this to a subsection under PS section
** Developmental difficulties

# TODO halogen difficulties
# TODO events stuff
# TODO refactoring stuff
# TODO too early abstractions


** Future of GGB

# TODO Native track?
# TODO configuration, dhall
# TODO cytoscape
# TODO extrapolate from ease of refactoring that extensibility & maintenance will be easier



* Conclusion


#+begin_comment
Encourage using PS with old JS projects

Case-study nature as a limitation;
will probably want to argue that the results are thanks in large part to the
nature of pure FP and PS; not merely happenstance even though n=1.

Also relatively "easy" because BD is open source and JS; it also has nearly
no external dependencies. Other legacy systems are likely to be much more
difficult to apply this approach to. Java/JVM has some tools and languages;
C or something becomes even more difficult.

Future work:
  Looking at open source projects; is functional OSS "better"?
#+end_comment




** Limitations and Future Work


# Bibliography

# \nocite{*}
\bibliographystyle{plainnat}
\bibliography{bibliography}
